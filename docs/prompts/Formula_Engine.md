UX of your estimation app so itâ€™s comprehensive, logically structured, and intuitive â€” allowing users to explore all four estimation models (Deterministic Formula, SAP Activate Heuristics, PERT, Monte Carlo, Analogy) before committing to one.

ğŸ§­ 1. Core Design Principle

The UX should follow the â€œProgressive Revealâ€ principle â€” show only whatâ€™s needed at each step, but ensure depth and transparency when the user expands details.

Visually: think Apple Keynote clarity + SAP Fiori logic + Airtable-style interactiveness.

âš™ï¸ 2. Recommended UX Flow (Step-by-Step)
Step 1 â€“ Project Definition

Purpose: Capture all quantifiable inputs.

Minimal Form Layout with smart defaults:

Base Effort (auto-filled from template or imported)

Modules selected â†’ auto-adds coefficients

of Legal Entities
of FTEs

Utilization Rate (%)

Overlap coefficients (optional, prefilled)

Country (auto-adjusts for localization factors, e.g. Malaysia e-Invoicing)

ğŸ§  Smart Defaults: Pre-populate with your baseline (475 MD, 5.6 FTE, 0.8 utilization).

âœ… Tip: Use expandable â€œinfo iâ€ tooltips for every parameter showing formula or justification (â€œOverlap ER = 0.25 means 25% of Explore overlaps with Realizeâ€).

Step 2 â€“ Model Selection Dashboard

Purpose: Users can choose one or more models to simulate.

Layout: 5-column card grid view, one per model.

Model What it does When to use Key Inputs Output Type
Deterministic Fast, formula-based Known effort/FTE Effort, FTE, Utilization Single date
Activate Heuristic Based on SAP Activate phases Standard S/4 Cloud rollout Scope size, sprints Timeboxed plan
PERT Probabilistic 3-point Uncertain estimates O, M, P per phase Range + confidence
Monte Carlo Risk distribution Volatile velocity Range + probability Histogram
Analogy Benchmarked vs past Repeatable rollout Reference dataset Similar case duration

Each card has a â€œSimulate â†’â€ button.

Step 3 â€“ Simulation Workspace

A split-screen interface with:

Left panel: Parameter sliders (Effort, FTE, Utilization, Overlap, Confidence, etc.)

Right panel: Live result cards and charts for all models.

ğŸ§© Each Model Output
Model Visualization Example
Deterministic Formula Waterfall or Gantt bar Shows overlapping phases with calculated days
SAP Activate Heuristic Sprint timeline Each sprint phase labelled
PERT Bell curve Shows expected, earliest, latest
Monte Carlo Histogram / cumulative probability â€œP80 = 5.2 monthsâ€
Analogy Comparison bar chart Shows your project vs 3 past averages

ğŸ”„ Allow users to toggle â€œCompare Modelsâ€ view, showing all five durations side-by-side.

Step 4 â€“ â€œConfidence & Riskâ€ Summary

Purpose: Let users interpret outcomes clearly.

Show as confidence-band cards:

ğŸ§® Deterministic: â€œBaseline plan: 4.1 months (fixed)â€

ğŸŸ¦ PERT: â€œExpected 4.2 months Â± 0.5 months (Ïƒ = 0.3)â€

ğŸŸ© Monte Carlo: â€œ90% chance to finish before 4.8 monthsâ€

ğŸŸ¨ Analogy: â€œMedian from 6 similar projects = 4.5 monthsâ€

ğŸ”µ Activate: â€œPlanned = 4 months (8 sprints Ã— 2 weeks)â€

Below that:

Traffic-light indicators (Green = likely on time, Amber = risk, Red = uncertain)

AI Insight card: â€œMonte Carlo indicates higher uncertainty due to low FTEsâ€”consider +1 consultant to achieve 4 month goal.â€

Step 5 â€“ Recommendation Engine

Display a â€œBest-fit Modelâ€ ribbon, determined by:

Completeness of data

Risk appetite (from user toggle)

Uncertainty level

Time vs accuracy priority

Example output:

â€œBased on your inputs (high certainty, single entity, no integration), Deterministic Formula offers optimal accuracy (Â±5%).
For risk calibration, add Monte Carlo overlay.â€

Step 6 â€“ Summary & Export

Combine all models into one â€œEstimation Summaryâ€ dashboard:

Interactive chart (duration vs confidence)

Tabular breakdown per model

Download PDF / Excel / JSON for audit

Auto-generate a Defensibility Report (for internal/external validation):

Shows formulas

Input assumptions

Output comparisons

Method references (SAP Activate, PERT, etc.)

ğŸ¨ 3. UX Design Style
Design Element Recommendation
Color Palette Soft blues + greys (professional, neutral)
Typography SF Pro / Inter / Roboto â€” clean and readable
Layout 2-column responsive; left = parameters, right = output
Icons Use Lucide or HeroIcons for intuitive symbols
Feedback Micro-animations (slide-in cards, dynamic recalculation)
Interactivity Sliders, dropdowns, toggles; no cluttered textboxes
Help Layer Collapsible sidebar explaining models, formulas, and references
ğŸ§® 4. Backend Logic to Support UX

Each model can share a unified data schema:

{
"project": {
"baseEffort": 475,
"fte": 5.6,
"utilization": 0.8,
"overlap": { "ER": 0.25, "RD": 0.3 },
"confidence": 0.9
},
"models": {
"deterministic": { "duration": 4.1 },
"activate": { "duration": 4.0 },
"pert": { "expected": 4.2, "min": 3.8, "max": 5.0 },
"montecarlo": { "p50": 4.1, "p90": 4.8 },
"analogy": { "median": 4.5, "range": [4.0, 5.0] }
}
}

This allows dynamic recalculation, charting, and export in real-time.

ğŸ’¡ 5. Practical Enhancements

AI Assistant Mode:
â€œBased on your scope, I recommend 5.5 FTE for a 4.1-month timeline. Shall I adjust?â€

Scenario Comparison Toggle:
â€œShow me 2 scenarios â€” 5 FTE vs 7 FTE.â€

Audit Mode:
For internal governance, print â€œCalculation lineageâ€ showing formula path.

SAP Integration (optional):
Sync inputs with SAP Readiness Check or Fit-to-Standard score to auto-fill effort.

ğŸ§­ 6. Summary: What Makes It Comprehensive Yet Friendly
Principle Implementation
Clarity Visualize each model separately and side-by-side
Comprehensiveness Capture all estimation types with one data model
Friendliness Use sliders, tooltips, color cues, and AI guidance
Auditability One-click export showing formulae and assumptions
Scalability Can expand to include cost, resource, or risk later
Defensibility Built-in references to SAP Activate, PERT, Monte Carlo theory

Would you like me to produce the UI/UX wireframe layout (with screen sections, flow arrows, and color-coded model cards) in Mermaid or React/Tailwind structure next â€” so your dev team can visualize and implement it?

You said:
What about the complete formula, users must know and able to justify the maths as well
ChatGPT said:

Perfect â€” since you want the users to see and justify the math, hereâ€™s how to make the complete formula framework visible, transparent, and defensible in the app (so every user understands exactly why the duration is what it is).

ğŸ§© 1. Formula Transparency Philosophy

The app should not just show a number â€” it should show the path to the number.
Every user must be able to trace:

Effort â†’ Duration â†’ Cost â†’ Duration by Phase (Prepare, Explore, Realize, Deploy, Run)

This ensures:

Defensibility: every figure can be explained in audit or negotiation.

Reproducibility: two consultants using the same inputs will always get the same outputs.

Education: clients and junior consultants can learn the relationship between parameters.

âš™ï¸ 2. The Core Duration Formula (Mathematical Model)

Your project duration derives from the total person-days (effort) divided by available full-time resources, adjusted for utilization and phase overlap.

Base Formula
Duration (months)
=
Total Effort (person-days)
FTE
Ã—
22
Ã—
Utilization
Ã—
Overlap Factor
Duration (months)=
FTEÃ—22Ã—Utilization
Total Effort (person-days)
â€‹

Ã—Overlap Factor

Where:

Total Effort: Sum of all module effort (from base or derived table)

FTE: Average full-time equivalents available

22: Average working days per month

Utilization: Actual productive % (e.g., 0.8 = 80%)

Overlap Factor: Adjustment for parallel activities (typically 0.75â€“0.9)

2.1 SAP Activate Phase Breakdown

Distribute duration using known SAP Activate benchmarks:

Phase % of Total Effort Typical Duration Ratio Key Drivers
Prepare 10% 0.5â€“1.0 months Project setup, onboarding
Explore 25% 1â€“1.5 months Fit-to-standard, workshops
Realize 45% 1.5â€“2.5 months Build, test, data load
Deploy 15% 0.5â€“1.0 months Cutover, go-live
Run (Hypercare) 5% 0.5 months Support, handover

Each phase can then be proportionally adjusted by Scope Breadth and Complexity Coefficients.

ğŸ§® 3. Full Extended Formula with Adjusted Multipliers
Effort Model
ğ¸
ğ‘¡
ğ‘œ
ğ‘¡
ğ‘
ğ‘™
=
ğ¸
ğ‘
ğ‘
ğ‘ 
ğ‘’
Ã—
(
1

- ğ‘†
  ğ‘
  )
  Ã—
  (
  1
- ğ‘ƒ
  ğ‘
  )
  Ã—
  (
  1
- ğ‘‚
  ğ‘ 
  )
  E
  total
  â€‹

=E
base
â€‹

Ã—(1+S
b
â€‹

)Ã—(1+P
c
â€‹

)Ã—(1+O
s
â€‹

)

Where:

ğ¸
ğ‘
ğ‘
ğ‘ 
ğ‘’
E
base
â€‹

: Base effort (475 MD in your case)

ğ‘†
ğ‘
S
b
â€‹

: Scope breadth coefficient (0â€“0.6 typical)

ğ‘ƒ
ğ‘
P
c
â€‹

: Process complexity (0â€“0.5 typical)

ğ‘‚
ğ‘ 
O
s
â€‹

: Organizational scale/geography (0â€“0.3 typical)

Duration Model
ğ·
=
ğ¸
ğ‘¡
ğ‘œ
ğ‘¡
ğ‘
ğ‘™
ğ¹
ğ‘‡
ğ¸
Ã—
22
Ã—
ğ‘ˆ
Ã—
(
1
âˆ’
ğ‘‚
ğ‘“
)
D=
FTEÃ—22Ã—U
E
total
â€‹

    â€‹

Ã—(1âˆ’O
f
â€‹

)

Where:

ğ‘ˆ
U: Utilization rate (e.g., 0.8)

ğ‘‚
ğ‘“
O
f
â€‹

: Overlap factor (e.g., 0.25â€“0.35 reduction for overlapping phases)

PMO Adjustment (Duration-Dependent Component)

PMO (and sometimes Basis) scales with duration, not effort:

ğ¸
ğ‘ƒ
ğ‘€
ğ‘‚
=
(
ğ·
in months
)
Ã—
ğ‘…
ğ‘ƒ
ğ‘€
ğ‘‚
E
PMO
â€‹

=(D in months)Ã—R
PMO
â€‹

Where
ğ‘…
ğ‘ƒ
ğ‘€
ğ‘‚
R
PMO
â€‹

= monthly PMO allocation (e.g., 15 MD/month)

Then total effort:

ğ¸
ğ‘¡
ğ‘œ
ğ‘¡
ğ‘
ğ‘™
=
ğ¸
ğ‘“
ğ‘¢
ğ‘›
ğ‘
ğ‘¡
ğ‘–
ğ‘œ
ğ‘›
ğ‘
ğ‘™

- ğ¸
  ğ‘¡
  ğ‘’
  ğ‘
  â„
  ğ‘›
  ğ‘–
  ğ‘
  ğ‘
  ğ‘™
- ğ¸
  ğ‘ƒ
  ğ‘€
  ğ‘‚
  E
  total
  â€‹

=E
functional
â€‹

+E
technical
â€‹

+E
PMO
â€‹

ğŸ“‰ 4. Model Comparison Layer (for Transparency)
Model Key Formula What It Shows Defensibility
Deterministic (yours)
ğ·
=
ğ¸
ğ¹
ğ‘‡
ğ¸
Ã—
22
Ã—
ğ‘ˆ
(
1
âˆ’
ğ‘‚
ğ‘“
)
D=
FTEÃ—22Ã—U
E
â€‹

(1âˆ’O
f
â€‹

) Direct relationship âœ… Easy to audit
SAP Activate Heuristic
ğ·
=
Î£
(
Phase Weight
Ã—
Sprint Count
)
D=Î£(Phase WeightÃ—Sprint Count) Uses SAP phase ratio âœ… SAP reference
PERT
ğ·
=
ğ‘‚

- 4
  ğ‘€
- ğ‘ƒ
  6
  D=
  6
  O+4M+P
  â€‹

      Probabilistic range	âš™ Good for uncertainty

  Monte Carlo Random sampling over PERT Probability curve (P50/P80) âš™ Statistically robust
  Analogy
  ğ·
  =
  ğ·
  ğ‘
  ğ‘£
  ğ‘”
  Ã—
  ğ¸
  ğ‘›
  ğ‘’
  ğ‘¤
  ğ¸
  ğ‘Ÿ
  ğ‘’
  ğ‘“
  D=D
  avg
  â€‹

Ã—
E
ref
â€‹

E
new
â€‹

    â€‹

    Based on similar projects	âš™ Contextual validation

ğŸ§  5. User Experience: Formula Visibility in the App

Interactive â€œShow Formulaâ€ Button

Hovering over the result (e.g. â€œ4.2 monthsâ€) expands a panel:

= (475 Ã— 1.0 Ã— 1.0 Ã— 1.0) / (5.6 Ã— 22 Ã— 0.8) Ã— 0.75
= 4.05 months

Then breakdown by phase (auto-generated):

Prepare: 0.4 | Explore: 1.0 | Realize: 2.0 | Deploy: 0.5 | Run: 0.2

Audit Tab (Formulas + Sources)

Shows:

Equation tree

References (e.g., SAP Activate Roadmap, PMI Estimation Guidelines)

Input history

Confidence range

Explainability Tooltip Example

â„¹ï¸ â€œDuration is derived from total person-days divided by available FTEs and adjusted for utilization and overlap. Overlap reduces total calendar time by 25%, as phases run concurrently.â€

âš–ï¸ 6. Formula Validation (Challenge Points)
Dimension Strength Weakness / Mitigation
Defensibility Based on person-days math, easy to trace Doesnâ€™t model uncertainty â€” pair with PERT
Practicality Matches SAP Activate delivery patterns Needs periodic calibration from project data
Scalability Simple scaling with FTE & entities May understate cross-entity coordination
Client Communication Simple and visual Might oversimplify concurrent streams
Mathematical Rigor Deterministic and reproducible Lacks stochastic range; can add Â±Ïƒ band
ğŸš€ 7. Suggested Visual Layout for â€œFormula Modeâ€
Section Description
Inputs Panel (left) All user-entered values (Effort, FTE, Utilization, Overlap)
Formula Renderer (center) Dynamic LaTeX-like output showing substituted formula
Result Summary (right) Duration in days, weeks, months + Gantt preview
Info Tabs (below) â€œExplain Formulaâ€, â€œPhase Breakdownâ€, â€œCompare Modelsâ€

Would you like me to compile this into a complete "Mathematical Logic Document" (structured like a spec sheet for your dev team + AI training reference), including:

Every formula (symbolic + substituted example)

Coefficient explanation table

Phase distribution ratios

Risk/uncertainty overlay logic (for PERT/Monte Carlo)

JSON schema for how app stores/uses each variable?

That would make your entire duration estimation logic auditable, trainable, and executable.

You said:
Yes
ChatGPT said:
Thought for 4 seconds
Mathematical Logic Specification â€” Duration & Effort Estimation (SAP S/4HANA Public Cloud, Greenfield)

Purpose: a complete, auditable spec your app (and any AI) can follow step-by-step to compute effort â†’ duration â†’ phase plan â†’ PMO impact, with optional risk overlays (PERT/Monte Carlo) and model comparisons. All symbols, units, and defaults are explicit. No hidden assumptions.

1. Definitions, Units, Conventions

Work day: weekday, 8 hours (but we compute in person-days to avoid mixing hours).

Working days / month: 22 (configurable).

Man-day (MD) = person-day.

FTE: average full-time consultants allocated concurrently (1.0 FTE â‰ˆ 22 MD/month at 100% utilization).

Utilization (U): productive fraction of an FTE (e.g., 0.80 = 80%).

Overlap: planned concurrency across phases/streams that reduces calendar duration without reducing effort.

1.1 Base Effort (your company baseline)

You provided the â€œfactory-independentâ€ (functional/technical) baseline and the wrapper team. We store both.

Functional & Technical stack (Base_FT):

FI1 (GL, CCA/PCA, Banking, Taxation) + AR Assist + E-Invoice: 86 MD

FI2 (AP, AR): 84 MD

FI3 (Asset Accounting + Migration Support): 61 MD

MM (Materials Management): 97 MD

Technical Development (forms & minor): 50 MD

Sum Base_FT = 86 + 84 + 61 + 97 + 50 = 378 MD

Project Wrapper (Factory/Wrappers):

Project Manager: 65 MD

Basis: 24 MD

Security & Authorization: 8 MD

Sum Wrapper = 97 MD

Grand Baseline (everything): 378 + 97 = 475 MD (4 months, includes hypercare per your baseline).

In calculations below we treat:

Base_FT (378 MD) as the scope-driven core (varies with scope/complexity).

Wrapper as duration-sensitive (PMO) and mostly duration-insensitive (Basis, S&A) unless otherwise stated.

2. Core Deterministic Model (Effort â†’ Duration)
   2.1 Total Effort (MD)

We split effort into:

Functional/Technical (E_FT) â€” varies with scope/complexity.

PMO (E_PMO) â€” varies with duration (month-rate).

Basis/S&A (E_BS, E_SA) â€” baseline fixed for Public Cloud (can be scaled by scope if desired).

ğ¸
FT
=
ğ¸
Base_FT
Ã—
(
1

- ğ‘†
  ğ‘
  )
  Ã—
  (
  1
- ğ‘ƒ
  ğ‘
  )
  Ã—
  (
  1
- ğ‘‚
  ğ‘ 
  )

ğ¸
BS
=
ğ¸
Basis, fixed
(
default
24
MD
)

ğ¸
SA
=
ğ¸
S&A, fixed
(
default
8
MD
)

ğ¸
PMO
=
ğ·
cal

(
months
)
Ã—
ğ‘…
PMO

(
MD/month
)

ğ¸
Total
=
ğ¸
FT

- ğ¸
  BS
- ğ¸
  SA
- ğ¸
  PMO
  E
  FT
  â€‹

E
BS
â€‹

E
SA
â€‹

E
PMO
â€‹

E
Total
â€‹

    â€‹

=E
Base_FT
â€‹

Ã—(1+S
b
â€‹

)Ã—(1+P
c
â€‹

)Ã—(1+O
s
â€‹

)
=E
Basis, fixed
â€‹

(default 24 MD)
=E
S&A, fixed
â€‹

(default 8 MD)
=D
cal
â€‹

(months)Ã—R
PMO
â€‹

(MD/month)
=E
FT
â€‹

+E
BS
â€‹

+E
SA
â€‹

+E
PMO
â€‹

    â€‹

Where:

ğ‘†
ğ‘
S
b
â€‹

= Scope Breadth coefficient (modules/process scope integration uplift).

ğ‘ƒ
ğ‘
P
c
â€‹

= Process Complexity coefficient (fit-to-standard deviation, light forms).

ğ‘‚
ğ‘ 
O
s
â€‹

= Org & Geography coefficient (entities, languages, countries).

ğ‘…
PMO
R
PMO
â€‹

= PMO monthly rate (MD/month).
Default: derive from your 65 MD over 4 months â†’ â‰ˆ 16.25 MD/month. You can round to 15â€“16.5 MD/month.

Note:
ğ¸
PMO
E
PMO
â€‹

depends on duration, which itself depends on effort. We resolve this with a simple fixed-point iteration (Section 6.3).

2.2 Scope Breadth Coefficient (
ğ‘†
ğ‘
S
b
â€‹

) â€” simple, auditable

Use whichever input users can provide. Two interchangeable options:

Option A (quick) â€” Module-level:

ğ‘†
ğ‘
=
ğ›¼
FI
â‹…
1
FI

- ğ›¼
  MM
  â‹…
  1
  MM
- ğ›¼
  SD
  â‹…
  1
  SD
- â‹¯
- âˆ‘
  (
  ğ›½
  â‹…
  integration_points
  )
  S
  b
  â€‹

=Î±
FI
â€‹

â‹…1
FI
â€‹

+Î±
MM
â€‹

â‹…1
MM
â€‹

+Î±
SD
â€‹

â‹…1
SD
â€‹

+â‹¯+âˆ‘(Î²â‹…integration_points)

Suggested defaults (calibrate over time):

ğ›¼
FI
=
0.00
Î±
FI
â€‹

=0.00 (already in base),
ğ›¼
MM
=
0.10
Î±
MM
â€‹

=0.10,
ğ›¼
SD
=
0.15
Î±
SD
â€‹

=0.15
Integrations (directional, at go-live):
ğ›½
=
0.02
to
0.05
Î²=0.02 to 0.05 per significant integration (your baseline: 0).

Option B (fine-grained) â€” L3 scope catalogue:

ğ‘†
ğ‘
=
âˆ‘
ğ‘–
âˆˆ
Scope Items
ğ‘¤
ğ‘–
â‹…
ğ‘¥
ğ‘–

- âˆ‘
  ğ‘—
  âˆˆ
  Integrations
  ğ›½
  ğ‘—
  S
  b
  â€‹

=
iâˆˆScope Items
âˆ‘
â€‹

w
i
â€‹

â‹…x
i
â€‹

- jâˆˆIntegrations
  âˆ‘
  â€‹

Î²
j
â€‹

ğ‘¥
ğ‘–
âˆˆ
{
0
,
1
}
x
i
â€‹

âˆˆ{0,1} indicates selected L3 scope item;
ğ‘¤
ğ‘–
w
i
â€‹

is that itemâ€™s uplift coefficient.

Provide the L3 table with
ğ‘¤
ğ‘–
w
i
â€‹

values in your app; your baseline can set all selected FI/MM standard items to 0 uplift (already priced in base).

Your current baseline (FI + MM, no integrations at go-live, manual e-invoicing & bank uploads):
Set
ğ‘†
ğ‘
=
0.00
S
b
â€‹

=0.00 unless MM breadth exceeds your baseline process pack (then add +0.05 to +0.10).

2.3 Process Complexity (
ğ‘ƒ
ğ‘
P
c
â€‹

)

For Public Cloud clean-core (no WRICEF beyond minor forms), keep this small and explicit:

ğ‘ƒ
ğ‘
=
ğ›¾
forms
â‹…
(forms_beyond_baseline)

- ğ›¾
  delta
  â‹…
  (
  1
  âˆ’
  GoToStandard%
  )
  P
  c
  â€‹

=Î³
forms
â€‹

â‹…(forms_beyond_baseline)+Î³
delta
â€‹

â‹…(1âˆ’GoToStandard%)

Baseline includes 4 forms (from your â€œTechnical Development 50 MDâ€).
If no extra forms: first term = 0.

ğ›¾
forms
Î³
forms
â€‹

typical 0.01â€“0.02 per extra form (light).

ğ›¾
delta
Î³
delta
â€‹

typical 0.10â€“0.25 when Fit-to-Standard adoption
<
80
%
<80%.
Your base assumption: 100% Fit-to-Standard â†’ second term = 0.

Your baseline:
ğ‘ƒ
ğ‘
=
0.00
P
c
â€‹

=0.00.

2.4 Org & Geography (
ğ‘‚
ğ‘ 
O
s
â€‹

)

Keep it deterministic with countable facts:

ğ‘‚
ğ‘ 
=
ğœ‚
LE
â‹…
(
active_LE
âˆ’
1
)

- ğœ‚
  country
  â‹…
  (
  countries
  âˆ’
  1
  )
- ğœ‚
  lang
  â‹…
  (
  languages
  âˆ’
  1
  )
  O
  s
  â€‹

=Î·
LE
â€‹

â‹…(active_LEâˆ’1)+Î·
country
â€‹

â‹…(countriesâˆ’1)+Î·
lang
â€‹

â‹…(languagesâˆ’1)

Defaults (public-cloud single country, English only):

ğœ‚
LE
=
0.03
Î·
LE
â€‹

=0.03,
ğœ‚
country
=
0.05
Î·
country
â€‹

=0.05,
ğœ‚
lang
=
0.02
Î·
lang
â€‹

=0.02

Dormant LEs: apply 0 unless in scope for config/testing.

Your baseline: 1 active LE, Malaysia only, English only â†’
ğ‘‚
ğ‘ 
=
0
O
s
â€‹

=0.

Your baseline:
ğ‘‚
ğ‘ 
=
0.00
O
s
â€‹

=0.00.

3. Duration Calculation
   3.1 Capacity (MD/month)
   Capacity
   =
   FTE
   Ã—
   22
   Ã—
   ğ‘ˆ
   Capacity=FTEÃ—22Ã—U

Your default baseline: FTE = choose based on plan (e.g., 5.6 FTE used earlier), U = 0.80.

3.2 Raw Duration (months, no overlap yet)
ğ·
raw
=
ğ¸
FT

- ğ¸
  BS
- ğ¸
  SA
  Capacity
  D
  raw
  â€‹

=
Capacity
E
FT
â€‹

+E
BS
â€‹

+E
SA
â€‹

    â€‹

3.3 Overlap factor

Represent the expected concurrency across phases/streams:

Overlap_factor
âˆˆ
[
0.65
,
1.00
]
Overlap_factorâˆˆ[0.65,1.00]

1.00 = strictly serial.

0.75 = 25% calendar reduction due to concurrency (typical).

We apply it to the calendar duration (not to effort).

3.4 Add PMO (duration-dependent) and iterate to consistency

Provisional duration (no PMO):

ğ·
0
=
ğ·
raw
Ã—
Overlap_factor
D
0
â€‹

=D
raw
â€‹

Ã—Overlap_factor

PMO effort:

ğ¸
PMO
=
ğ·
0
Ã—
ğ‘…
PMO
E
PMO
â€‹

=D
0
â€‹

Ã—R
PMO
â€‹

Recompute duration including PMO:

ğ·
1
=
ğ¸
FT

- ğ¸
  BS
- ğ¸
  SA
- ğ¸
  PMO
  Capacity
  Ã—
  Overlap_factor
  D
  1
  â€‹

=
Capacity
E
FT
â€‹

+E
BS
â€‹

+E
SA
â€‹

+E
PMO
â€‹

    â€‹

Ã—Overlap_factor

Fixed-point iteration: Repeat 2â€“3 using
ğ·
1
D
1
â€‹

in place of
ğ·
0
D
0
â€‹

until
âˆ£
ğ·
ğ‘˜

- 1
  âˆ’
  ğ·
  ğ‘˜
  âˆ£
  <
  ğœ€
  âˆ£D
  k+1
  â€‹

âˆ’D
k
â€‹

âˆ£<Îµ (e.g., 0.01 months).
This converges rapidly because PMO is linear in D.

In most cases, 1â€“2 iterations reach stability.

4. Phase Breakdown (SAP Activate) â€” turning months into a plan

Assign total effort and calendar by phase using weights, then compress/overlap as per your delivery style.

4.1 Default phase effort weights (can be tuned)

Prepare: 10%

Explore: 25%

Realize: 45%

Deploy: 15%

Run (Hypercare): 5% (your baseline = 4 weeks; you can pin Run to 0.5â€“1.0 month)

ğ¸
phase
=
ğ¸
Total
Ã—
ğ‘¤
phase
E
phase
â€‹

=E
Total
â€‹

Ã—w
phase
â€‹

4.2 Phase calendar

Use either:

Proportional by effort:

ğ·
phase
=
ğ·
Ã—
ğ‘¤
phase
D
phase
â€‹

=DÃ—w
phase
â€‹

Sprint-box heuristic (two-week sprints, e.g., Explore = 2â€“3 sprints, Realize = 4â€“6 sprints) for a cleaner timeline.

Your presentation style (Apple-like) may prefer the sprint-box view; the engine still uses the proportional math for totals.

5. Training & Testing â€” session-based controls (fits your policy)

TTT sessions drive calendar slots, not huge effort swings (since you provide TTT):

Lock 2 sessions baseline (Finance + Procurement/MM).

If users pick 3 sessions, add a small
ğ‘†
ğ‘
S
b
â€‹

uplift (e.g., +0.01) or inject a fixed 2â€“4 MD per extra session into
ğ¸
FT
E
FT
â€‹

.

User count does not materially change effort if sessions are controlled (your policy). Keep a guardrail:

For > 15 attendees/session, show a UI hint (â€œSplit recommendedâ€), but no automatic effort increase unless the user opts to add a second run.

6. Algorithms (step-by-step) & Pseudocode
   6.1 Inputs (minimum viable)

Base_FT_MD = 378

Wrapper_Basis_MD = 24

Wrapper_SA_MD = 8

PMO_month_rate = 16.25 (MD/month; configurable)

S_b, P_c, O_s (coefficients) â€” defaults = 0.0

FTE, Utilization (U), Overlap_factor

WDPM = 22 (working days per month)

Phase_weights = {0.10, 0.25, 0.45, 0.15, 0.05}

6.2 Derived values
Capacity = FTE _ WDPM _ U
E*FT = Base_FT_MD * (1 + S*b) * (1 + P_c) \* (1 + O_s)
E_fixed = Wrapper_Basis_MD + Wrapper_SA_MD

6.3 Iteration for PMO & Duration
D0 = ((E*FT + E_fixed) / Capacity) * Overlap*factor
repeat:
E_PMO = D0 * PMO_month_rate
D1 = ((E_FT + E_fixed + E_PMO) / Capacity) \* Overlap_factor
if abs(D1 - D0) < 0.01: break
D0 = D1
D = D1
E_Total = E_FT + E_fixed + E_PMO

6.4 Phase breakdown
for each phase p:
E*phase[p] = E_Total * weight[p]
D*phase[p] = D * weight[p] # proportional method

7. Risk/Uncertainty Overlays (optional but recommended)
   7.1 PERT per phase (3-point input)

For each phase
ğ‘
p: optimistic
ğ‘‚
ğ‘
O
p
â€‹

, most-likely
ğ‘€
ğ‘
M
p
â€‹

, pessimistic
ğ‘ƒ
ğ‘
P
p
â€‹

ğ·
ğ‘
,
PERT
=
ğ‘‚
ğ‘

- 4
  ğ‘€
  ğ‘
- ğ‘ƒ
  ğ‘
  6

ğœ
ğ‘
=
ğ‘ƒ
ğ‘
âˆ’
ğ‘‚
ğ‘
6

ğ·
PERT
=
âˆ‘
ğ‘
ğ·
ğ‘
,
PERT

ğœ
total
=
âˆ‘
ğ‘
ğœ
ğ‘
2
D
p,PERT
â€‹

Ïƒ
p
â€‹

D
PERT
â€‹

Ïƒ
total
â€‹

    â€‹

=
6
O
p
â€‹

+4M
p
â€‹

+P
p
â€‹

    â€‹

=
6
P
p
â€‹

âˆ’O
p
â€‹

    â€‹

=
p
âˆ‘
â€‹

D
p,PERT
â€‹

=
p
âˆ‘
â€‹

Ïƒ
p
2
â€‹

    â€‹

    â€‹

Present
ğ‘ƒ
50
â‰ˆ
ğ·
PERT
P50â‰ˆD
PERT
â€‹

,
ğ‘ƒ
80
â‰ˆ
ğ·
PERT

- 0.84
  â‹…
  ğœ
  total
  P80â‰ˆD
  PERT
  â€‹

  +0.84â‹…Ïƒ
  total
  â€‹

.

7.2 Monte Carlo (portfolio risk)

Sample each phase duration from a beta or triangular distribution with (O, M, P).

Run N=5,000 trials; compute P50/P80 and display a histogram + cumulative curve.

Keep base deterministic as the median; overlays explain uncertainty, not replace the core.

8. Alternative Duration Models (for comparison in the app)
   Model Formula Inputs Output
   Deterministic (this spec)
   ğ·
   D via effort/capacity + iteration on PMO Base_FT, coeffs, FTE, U, overlap, PMO rate Single duration + phase split
   SAP Activate Heuristic
   ğ·
   =
   âˆ‘
   sprints
   Ã—
   0.5
   month
   D=âˆ‘sprintsÃ—0.5 month Sprint counts per phase Time-boxed plan
   PERT
   âˆ‘
   (
   ğ‘‚

- 4
  ğ‘€
- ğ‘ƒ
  )
  /
  6
  âˆ‘(O+4M+P)/6 3-point per phase Mean + Ïƒ, P50/P80
  Analogy
  ğ·
  =
  ğ·
  ref
  Ã—
  ğ¸
  new
  ğ¸
  ref
  D=D
  ref
  â€‹

Ã—
E
ref
â€‹

E
new
â€‹

    â€‹

    Reference project(s)	Duration anchored to past

Monte Carlo simulate PERT 3-point per phase + N Probability curve

Your app should show all side-by-side and recommend one based on data completeness & risk appetite.

9. Worked Example (your current baseline)

Given:

ğ¸
Base_FT
=
378
E
Base_FT
â€‹

=378 MD

ğ¸
BS
=
24
E
BS
â€‹

=24,
ğ¸
SA
=
8
E
SA
â€‹

=8 MD

ğ‘†
ğ‘
=
0
S
b
â€‹

=0,
ğ‘ƒ
ğ‘
=
0
P
c
â€‹

=0,
ğ‘‚
ğ‘ 
=
0
O
s
â€‹

=0

FTE = 5.6,
ğ‘ˆ
=
0.80
U=0.80, Overlap_factor=0.75

ğ‘…
PMO
=
16.25
R
PMO
â€‹

=16.25 MD/month, WDPM = 22

Step 1 â€” Capacity:
5.6
Ã—
22
Ã—
0.8
=
98.56
MD/month
5.6Ã—22Ã—0.8=98.56 MD/month

Step 2 â€” Provisional duration (no PMO):

ğ·
0
=
378

- 24
- 8
  98.56
  Ã—
  0.75
  =
  410
  98.56
  Ã—
  0.75
  â‰ˆ
  4.16
  Ã—
  0.75
  â‰ˆ
  3.12
  months
  D
  0
  â€‹

=
98.56
378+24+8
â€‹

Ã—0.75=
98.56
410
â€‹

Ã—0.75â‰ˆ4.16Ã—0.75â‰ˆ3.12 months

Step 3 â€” PMO:

ğ¸
PMO
=
3.12
Ã—
16.25
â‰ˆ
50.7
MD
E
PMO
â€‹

=3.12Ã—16.25â‰ˆ50.7 MD

Step 4 â€” Recompute:

ğ·
1
=
410

- 50.7
  98.56
  Ã—
  0.75
  =
  460.7
  98.56
  Ã—
  0.75
  â‰ˆ
  4.68
  Ã—
  0.75
  â‰ˆ
  3.51
  months
  D
  1
  â€‹

=
98.56
410+50.7
â€‹

Ã—0.75=
98.56
460.7
â€‹

Ã—0.75â‰ˆ4.68Ã—0.75â‰ˆ3.51 months

Step 5 â€” Iterate once more:

ğ¸
PMO
â€²
=
3.51
Ã—
16.25
â‰ˆ
57.0
MD
E
PMO
â€²
â€‹

=3.51Ã—16.25â‰ˆ57.0 MD
ğ·
2
=
410

- 57.0
  98.56
  Ã—
  0.75
  =
  467.0
  98.56
  Ã—
  0.75
  â‰ˆ
  4.74
  Ã—
  0.75
  â‰ˆ
  3.56
  months
  D
  2
  â€‹

=
98.56
410+57.0
â€‹

Ã—0.75=
98.56
467.0
â€‹

Ã—0.75â‰ˆ4.74Ã—0.75â‰ˆ3.56 months

Change < 0.05 months â†’ converged.

Totals:

ğ·
â‰ˆ
3.56
Dâ‰ˆ3.56 months (â‰ˆ 3.6 months)

ğ¸
PMO
â‰ˆ
57
E
PMO
â€‹

â‰ˆ57 MD

ğ¸
Total
=
378

- 24
- 8
- # 57
  467

ğ‘€
ğ·
E
Total
â€‹

=378+24+8+57=467 MD

Phase effort (@10/25/45/15/5%):

Prepare 46.7 MD | Explore 116.8 | Realize 210.2 | Deploy 70.1 | Run 23.4

Phase calendar (proportional):

Prepare 0.36 mo | Explore 0.89 | Realize 1.60 | Deploy 0.53 | Run 0.18

If you pin Run to fixed 4 weeks (â‰ˆ 0.9 mo), adjust others proportionally or extend D accordingly. Your baseline 4 months likely assumes a longer Run window and/or slightly lower overlap.

10. JSON I/O Schema (for your app & AI)
    10.1 Input JSON
    {
    "constants": {
    "wdpm": 22,
    "defaultUtilization": 0.8,
    "defaultOverlap": 0.75,
    "pmoMonthRate": 16.25
    },
    "baseline": {
    "baseFT": 378,
    "basis": 24,
    "securityAuth": 8
    },
    "coefficients": {
    "scopeBreadth": 0.00,
    "processComplexity": 0.00,
    "orgGeo": 0.00
    },
    "capacity": {
    "fte": 5.6,
    "utilization": 0.8
    },
    "overlap": {
    "factor": 0.75
    },
    "phaseWeights": {
    "prepare": 0.10,
    "explore": 0.25,
    "realize": 0.45,
    "deploy": 0.15,
    "run": 0.05
    },
    "training": {
    "tttSessions": 2
    }
    }

10.2 Output JSON
{
"effort": {
"ft": 378,
"basis": 24,
"securityAuth": 8,
"pmo": 57.0,
"total": 467.0
},
"duration": {
"months": 3.56,
"days": 3.56 \* 22
},
"phase": {
"prepare": { "effort": 46.7, "months": 0.36 },
"explore": { "effort": 116.8, "months": 0.89 },
"realize": { "effort": 210.2, "months": 1.60 },
"deploy": { "effort": 70.1, "months": 0.53 },
"run": { "effort": 23.4, "months": 0.18 }
},
"audit": {
"capacityMdPerMonth": 98.56,
"overlapFactor": 0.75,
"iteration": 2,
"formulaVersion": "v1.0"
}
}

11. Challenging & Calibrating the Formula (what to watch)

PMO dependence on duration: modeled explicitly via iteration â€” good.
Risk: if client governance is heavy, consider making
ğ‘…
PMO
R
PMO
â€‹

a function of #stakeholders or #workstreams.

Overlap realism: 0.75 is powerful; ensure your team can truly run streams in parallel. Tie overlap to FTE â‰¥ threshold (e.g., if FTE < 4.0, cap overlap at 0.85).

Org/Geo coefficient: simple and deterministic; refine with per-country packs (e.g., extra statutory reports â†’ add +0.02 per pack actually used).

Training sessions: keep effort fixed but reserve calendar slots (they influence scheduling not volume).

Run (Hypercare): if you pin to 4 weeks, either expand D or pre-compress other phases.

Sensitivity: expose sliders for FTE and Overlap; show how PMO grows with longer D to support trade-off conversations.

12. How to explain the math to end-users (UI copy)

â€œWe turn person-days into calendar months by dividing by your teamâ€™s throughput (FTE Ã— working days Ã— utilization) and crediting planned concurrency (overlap). PMO scales with months on project, so we solve duration iteratively until the math balances.â€

â€œScope Breadth, Process Complexity, Org/Geography are coefficients multiplying your base functional/technical effort. Each is driven by countable facts: selected scope items, forms beyond baseline, active entities/countries/languages.â€

â€œEverything is traceable. Click â€˜Show Mathâ€™ to see substituted formulas and each coefficientâ€™s source.â€

13. Quick checklist for implementation

Compute Capacity.

Compute E_FT from Base_FT Ã— (1 + coefficients).

Add fixed Basis & S&A.

Compute provisional D (no PMO), apply Overlap.

Add PMO = D Ã— monthly rate, recompute D, iterate to converge.

Derive phase effort & phase months.

(Optional) Run PERT/Monte Carlo overlays.

Render audit trail (substituted formulas + values).
